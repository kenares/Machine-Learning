{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOCIETE GENERALE\n",
    "The aim of this challenge is to predict the Crude Oil production's trend base on the previous year Crude Oil data.\n",
    "\n",
    "That would help the compagny to predict the revenue generated by the Trade Finance business line\n",
    "\n",
    "Understanding the variation of the product per region helps in predicting the Oil price trend in these regions.\n",
    "\n",
    "The objective is to predict the probability of increase of Crude Oil production per quarter per contry.\n",
    "\n",
    "TODO : \n",
    "    1. Data analysis\n",
    "    2. Neural Network\n",
    "    3. RandomForestClassifier with bagging and random feature subset\n",
    "    4. 4\n",
    "    5. 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from useful import useful\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "root = r\"/Users/Kenneth-Aristide/anaconda3/bin/python_prog/ML/styles/bmh_matplotlibrc.json\"\n",
    "s = json.load(open(root))\n",
    "matplotlib.rcParams.update(s)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1_diffClosing stocks(kmt)</th>\n",
       "      <th>1_diffExports(kmt)</th>\n",
       "      <th>1_diffImports(kmt)</th>\n",
       "      <th>1_diffRefinery intake(kmt)</th>\n",
       "      <th>1_diffWTI</th>\n",
       "      <th>1_diffSumClosing stocks(kmt)</th>\n",
       "      <th>1_diffSumExports(kmt)</th>\n",
       "      <th>1_diffSumImports(kmt)</th>\n",
       "      <th>1_diffSumProduction(kmt)</th>\n",
       "      <th>...</th>\n",
       "      <th>county_68</th>\n",
       "      <th>county_69</th>\n",
       "      <th>county_70</th>\n",
       "      <th>county_71</th>\n",
       "      <th>county_72</th>\n",
       "      <th>county_73</th>\n",
       "      <th>county_74</th>\n",
       "      <th>county_75</th>\n",
       "      <th>county_76</th>\n",
       "      <th>actual_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10154</th>\n",
       "      <td>ID10155</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.80</td>\n",
       "      <td>-469.1997</td>\n",
       "      <td>-6034.6239</td>\n",
       "      <td>-1237.4344</td>\n",
       "      <td>1475.3527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>ID10156</td>\n",
       "      <td>209.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>525.0000</td>\n",
       "      <td>-506.0000</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>5567.0593</td>\n",
       "      <td>2212.8782</td>\n",
       "      <td>4247.3021</td>\n",
       "      <td>14104.9032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10156</th>\n",
       "      <td>ID10157</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>5.82</td>\n",
       "      <td>4256.6040</td>\n",
       "      <td>-6163.9167</td>\n",
       "      <td>5479.7160</td>\n",
       "      <td>-174.7942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10157</th>\n",
       "      <td>ID10158</td>\n",
       "      <td>-361.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-746.0000</td>\n",
       "      <td>-13.0000</td>\n",
       "      <td>4.89</td>\n",
       "      <td>644.1414</td>\n",
       "      <td>-4513.0417</td>\n",
       "      <td>-21586.6926</td>\n",
       "      <td>-1420.9013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>ID10159</td>\n",
       "      <td>-252.4286</td>\n",
       "      <td>-487.1428</td>\n",
       "      <td>8.8571</td>\n",
       "      <td>1049.5714</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>7872.1638</td>\n",
       "      <td>1455.8212</td>\n",
       "      <td>8591.6520</td>\n",
       "      <td>4178.0130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  1_diffClosing stocks(kmt)  1_diffExports(kmt)  \\\n",
       "10154  ID10155                     0.0000              0.0000   \n",
       "10155  ID10156                   209.0000              0.0000   \n",
       "10156  ID10157                    23.0000              0.0000   \n",
       "10157  ID10158                  -361.0000              0.0000   \n",
       "10158  ID10159                  -252.4286           -487.1428   \n",
       "\n",
       "       1_diffImports(kmt)  1_diffRefinery intake(kmt)  1_diffWTI  \\\n",
       "10154              0.0000                      0.0000       6.80   \n",
       "10155            525.0000                   -506.0000      -3.41   \n",
       "10156             20.0000                     12.0000       5.82   \n",
       "10157           -746.0000                    -13.0000       4.89   \n",
       "10158              8.8571                   1049.5714      -0.37   \n",
       "\n",
       "       1_diffSumClosing stocks(kmt)  1_diffSumExports(kmt)  \\\n",
       "10154                     -469.1997             -6034.6239   \n",
       "10155                     5567.0593              2212.8782   \n",
       "10156                     4256.6040             -6163.9167   \n",
       "10157                      644.1414             -4513.0417   \n",
       "10158                     7872.1638              1455.8212   \n",
       "\n",
       "       1_diffSumImports(kmt)  1_diffSumProduction(kmt)      ...        \\\n",
       "10154             -1237.4344                 1475.3527      ...         \n",
       "10155              4247.3021                14104.9032      ...         \n",
       "10156              5479.7160                 -174.7942      ...         \n",
       "10157            -21586.6926                -1420.9013      ...         \n",
       "10158              8591.6520                 4178.0130      ...         \n",
       "\n",
       "       county_68  county_69  county_70  county_71  county_72  county_73  \\\n",
       "10154        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "10155        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "10156        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "10157        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "10158        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       county_74  county_75  county_76  actual_labels  \n",
       "10154        0.0        0.0        0.0              1  \n",
       "10155        0.0        0.0        0.0              1  \n",
       "10156        0.0        0.0        0.0              1  \n",
       "10157        0.0        0.0        0.0              0  \n",
       "10158        0.0        0.0        1.0              0  \n",
       "\n",
       "[5 rows x 210 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalized_data(data, columns):\n",
    "    \"\"\"\n",
    "    Convenience function: \n",
    "        Normalized data for a Neural Network\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        data[col] = (data[col] - data[col].mean()) / data[col].std()\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def data_cleaner(root):\n",
    "    \"\"\"\n",
    "    Convenience function : \n",
    "        load the data\n",
    "        find if they're nan value in columns, if True fill with the median\n",
    "        create boolean indicator for each month and county\n",
    "        return a test and the new dataset\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(root, sep = ';')\n",
    "    bool_object = data.isnull().any()\n",
    "    bool_object = bool_object.loc[bool_object == True]\n",
    "    nan_list = bool_object.index\n",
    "    for col in nan_list:\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "        \n",
    "    dummies_months = pd.get_dummies(data['month'], prefix = 'month')\n",
    "    dummies_counties = pd.get_dummies(data['country'], prefix = 'county')\n",
    "    _data = pd.concat([data, dummies_months, dummies_counties], axis = 1)\n",
    "    _data = _data.drop(['country', 'month'], axis = 1)\n",
    "    \n",
    "    return _data.isnull().any().any(), _data, data\n",
    "\n",
    "\n",
    "root = '/Users/Kenneth-Aristide/anaconda3/bin/python_prog/ML_Training/data/BankSG.csv'\n",
    "test, bank_data, bank = data_cleaner(root)\n",
    "\n",
    "# load the label\n",
    "bank_label = pd.read_csv('/Users/Kenneth-Aristide/anaconda3/bin/python_prog/ML_Training/data/SGLabels.csv',\n",
    "                         sep = ';')\n",
    "\n",
    "# add the label to the data\n",
    "bank_data['actual_labels'] = bank_label.Target\n",
    "print(test)\n",
    "bank_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_to_normalized = list(bank.columns)\n",
    "col_to_normalized.remove('ID')\n",
    "col_to_normalized.remove('month')\n",
    "col_to_normalized.remove('country')\n",
    "bank_data = normalized_data(bank_data, col_to_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_root = '/Users/Kenneth-Aristide/anaconda3/bin/python_prog/ML_Training/data/Test.csv'\n",
    "_data = pd.read_csv(_root, sep = ';')\n",
    "test, bank_test, bankTest = data_cleaner(_root)\n",
    "bank_test = normalized_data(bank_test, col_to_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 209)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_test = bank_test[best_features_list]\n",
    "bank_test['ones'] = np.ones(bank_test.shape[0])\n",
    "X_new = bank_test.values\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find the top  best predictors for the crude Oil production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_diffExports(kmt)', '7_diffSumProduction(kmt)', '12_diffSumExports(kmt)', '7_diffSumRefinery intake(kmt)', '1_diffSumImports(kmt)', '12_diffSumRefinery intake(kmt)', '1_diffSumRefinery intake(kmt)', '12_diffSumProduction(kmt)', '1_diffSumExports(kmt)', '1_diffSumProduction(kmt)']\n"
     ]
    }
   ],
   "source": [
    "features = list(bank_data.columns)\n",
    "features.remove('ID')\n",
    "features.remove('actual_labels')\n",
    "\n",
    "best_features_dict, best_features_list = useful.find_best_column(bank_data, 'actual_labels', features)\n",
    "print(best_features_list[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorelation check\n",
    "Here I would study the autocorelation between all the variable describing one month of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_features = [elem for elem in best_features_list if 'diffSum' in elem or 'month' in elem or 'county' in elem]\n",
    "new_features_bis = new_features.copy()\n",
    "new_features_bis.append('actual_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10159, 200) (10159,)\n"
     ]
    }
   ],
   "source": [
    "#new_features.remove('actual_labels')\n",
    "_bank_data = bank_data[best_features_list[-199:]]\n",
    "_bank_data['ones'] = np.ones(bank_data.shape[0])\n",
    "\n",
    "X = _bank_data.values\n",
    "y = bank_data['actual_labels'].values.astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly initialize the thetas (weights)\n",
    "theta_init = np.random.normal(0, 0.01, size = (X.shape[1], 1))\n",
    "\n",
    "def sigmoid_activation(x, theta):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "        compute the activation of the NNet\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    theta = np.asarray(theta)\n",
    "    return 1 / (1 + np.exp(-np.dot(theta.T, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NNet3:\n",
    "    def __init__(self, learning_rate=0.5, maxepochs=1e4, convergence_thres=1e-5):\n",
    "        \"\"\"\n",
    "        Convenience function:\n",
    "            initialize the NNet parameters\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.maxepochs = int(maxepochs)\n",
    "        self.convergence_thres = 1e-5\n",
    "        \n",
    "    def multiplecost(self, X, y):\n",
    "        l1, l2 = self.feedforward(X)\n",
    "        inner = y * np.log(l2) + (1 - y) * np.log(1- l2)\n",
    "        return -np.mean(inner)\n",
    "    \n",
    "    def sigmoid_activation(self, X, theta):\n",
    "        X = np.asarray(X)\n",
    "        theta = np.asarray(theta)\n",
    "        return 1 / (1 + np.exp(-np.dot(theta.T, X)))\n",
    "    \n",
    "    def feedforward(self, X):\n",
    "        l1 = self.sigmoid_activation(X.T, self.theta0).T\n",
    "        l1 = np.column_stack([np.ones(l1.shape[0]), l1])\n",
    "        l2 = self.sigmoid_activation(l1.T, self.theta1)\n",
    "        return l1, l2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        _, y = self.feedforward(X)\n",
    "        return y\n",
    "    \n",
    "    def learn(self, X, y):\n",
    "        nobs, ncols = X.shape\n",
    "        self.theta0 = np.random.normal(0, 0.01, size = (ncols, 500))\n",
    "        self.theta1 = np.random.normal(0, 0.01, size = (501, 1))\n",
    "\n",
    "        self.costs = []\n",
    "        cost = self.multiplecost(X, y)\n",
    "        self.costs.append(cost)\n",
    "        costprev = cost + self.convergence_thres + 1\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        for counter in np.arange(self.maxepochs):\n",
    "            l1, l2 = self.feedforward(X)\n",
    "            \n",
    "            # Backpropagation\n",
    "            l2_delta = (y - l2) * l2 * (1 - l2)\n",
    "            l1_delta =  l2_delta.T.dot(self.theta1.T) * l1 * (1 - l1)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.theta1 += l1.T.dot(l2_delta.T) / nobs * self.learning_rate\n",
    "            self.theta0 += X.T.dot(l1_delta)[:, 1:] / nobs * self.learning_rate\n",
    "            \n",
    "            counter += 1\n",
    "            costprev = cost\n",
    "            cost = self.multiplecost(X, y)\n",
    "            self.costs.append(cost)\n",
    "            if np.abs(costprev - cost) < self.convergence_thres and counter > 500:\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta_1_init = np.random.normal(0, 0.01, size = (X.shape[1], 500))\n",
    "a2 = sigmoid_activation(X.T, theta_1_init)\n",
    "theta_2_init = np.random.normal(0, 0.01, size = (X.shape[0], 500))\n",
    "a3 = sigmoid_activation(a2.T, theta_2_init)\n",
    "theta_3_init = np.random.normal(0, 0.01, size = (500, 1))\n",
    "a4 = sigmoid_activation(a3.T, theta_3_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10159, 200)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 500)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_1_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10159)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 29min 52s, sys: 19min 19s, total: 1h 49min 12s\n",
      "Wall time: 1h 1min 6s\n",
      "Train score : 0.8293712596094763 \n",
      " Test score : 0.8159876120930579\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "split = math.floor(X.shape[0] * .8)\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]\n",
    "\n",
    "\n",
    "learning_rate = 0.5\n",
    "maxepochs = 10000\n",
    "convergence_thres = 0.00001\n",
    "\n",
    "_model = NNet3(learning_rate = learning_rate, maxepochs = maxepochs, convergence_thres = convergence_thres)\n",
    "\n",
    "%time _model.learn(X_train, y_train)\n",
    "probabilities_test = _model.predict(X_test)\n",
    "probabilities_train = _model.predict(X_train)\n",
    "auc_train = roc_auc_score(y_train, probabilities_train[0])\n",
    "auc_test = roc_auc_score(y_test, probabilities_test[0])\n",
    "print(\"Train score : {0} \\n Test score : {1}\".format(auc_train, auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = _model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def singlecost(X, y, theta):\n",
    "    \"\"\"\n",
    "    Convenience function :\n",
    "        compute the cost for a single observation\n",
    "    \"\"\"\n",
    "    h = sigmoid_activation(X.T, theta)\n",
    "    return - np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "\n",
    "cost_0 = singlecost(X[0], y[0], theta_init)\n",
    "cost_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's compute the gradients for each parameter of the model\n",
    "grads = np.zeros(theta_init.shape)\n",
    "n = X.shape[0]\n",
    "\n",
    "for j , obs in enumerate(X):\n",
    "    h = sigmoid_activation(obs, theta_init)\n",
    "    delta = (y[j] - h) * h * (1 - h ) * obs\n",
    "    grads += delta[:, np.newaxis] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# two layer neural network\n",
    "learning_rate = 0.1\n",
    "maxepochs = 10000\n",
    "convergence_thres = 0.0001\n",
    "\n",
    "def learn(X, y, theta, learning_rate, maxepochs, convergence_thres):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "        learn a two layer Neural Networks\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    cost = singlecost(X, y, theta)\n",
    "    costprev = cost + convergence_thres + 0.01\n",
    "    counter = 0\n",
    "    \n",
    "    for counter in np.arange(maxepochs):\n",
    "        grads = np.zeros(theta.shape)\n",
    "        for j, obs in enumerate(X):\n",
    "            h = sigmoid_activation(obs, theta)\n",
    "            delta = (y[j] - h)* h *(1 - h) * obs\n",
    "            grads += delta[:, np.newaxis] / X.shape[0]\n",
    "            \n",
    "        theta += grads * learning_rate\n",
    "        counter += 1\n",
    "        costprev = cost\n",
    "        cost = singlecost(X, y, theta)\n",
    "        costs.append(cost)\n",
    "        if np.abs(costprev - cost) < convergence_thres:\n",
    "            break\n",
    "            \n",
    "            \n",
    "    figsize(12.5, 5)\n",
    "    plt.plot(costs)\n",
    "    plt.title(\"Convergence of the cost function for a two layers NNets\")\n",
    "    plt.ylabel(\"J($\\Theta$)\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.legend();\n",
    "    return theta, costs\n",
    "\n",
    "theta, costs = learn(X, y, theta_init, learning_rate, maxepochs, convergence_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward_4(x, theta_0, theta_1, theta_2):\n",
    "    \"\"\"\n",
    "    Convenience function\n",
    "        compute the output of a 4 layer NNets\n",
    "    \"\"\"\n",
    "    a1 = sigmoid_activation(x.T, theta_0).T\n",
    "    a1 = np.column_stack([np.ones(a1.shape[0]), a1])\n",
    "    a2 =  sigmoid_activation(a1.T, theta_1).T\n",
    "    a2 = np.column_stack([np.ones(a2.shape[0]), a2])\n",
    "    out = sigmoid_activation(a2.T, theta_2)\n",
    "    return a1, a2, out\n",
    "\n",
    "theta0_init = np.random.normal(0, 0.01, size = (X.shape[1], (X.shape[1] - 1)))\n",
    "theta1_init = np.random.normal(0, 0.01, size = (X.shape[1], (X.shape[1] - 1)))\n",
    "theta2_init = np.random.normal(0, 0.01, size = (X.shape[1], 1))\n",
    "\n",
    "l1, l2, l3 = feedforward_4(X, theta0_init, theta1_init, theta2_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l3_delta = l3 - y\n",
    "l2_delta = l3_delta.T.dot(theta2_init.T) * l2 * (1 - l2)\n",
    "l1_delta = (l2_delta.dot(theta1_init)).T.dot((l1 * (1 - l1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((l1 * l2_delta) / X.shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta1_init .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiplecost(X, y, theta0, theta1, theta2, lambda_):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "        compute the cost of a 4 layer NNets\n",
    "    \"\"\"\n",
    "    _, __, h = feedforward_4(X, theta0, theta1, theta2)\n",
    "    reg_term = (sum(sum(theta0_init ** 2)) + sum(sum(theta1_init ** 2)) + \\\n",
    "                sum(sum(theta2_init ** 2)) ) * (lambda_ / (2 * X.shape[0]))\n",
    "    return -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h)) + reg_term\n",
    "\n",
    "c = multiplecost(X, y, theta0_init, theta1_init, theta2_init, 1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward_3(x, theta_0, theta_1):\n",
    "    \"\"\"\n",
    "    Convenience function\n",
    "        compute the output of a 3 layer NNets\n",
    "    \"\"\"\n",
    "    a1 = sigmoid_activation(x.T, theta_0).T\n",
    "    a1 = np.column_stack([np.ones(a1.shape[0]), a1])\n",
    "    out = sigmoid_activation(a1.T, theta_1)\n",
    "    return out\n",
    "\n",
    "theta0_init = np.random.normal(0, 0.01, size = (X.shape[1], (X.shape[1] - 1)))\n",
    "theta1_init = np.random.normal(0, 0.01, size = (X.shape[1], 1))\n",
    "\n",
    "\n",
    "h = feedforward_3(X, theta0_init, theta1_init)\n",
    "h                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _multiplecost(X, y, theta0, theta1):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "        compute the cost of a 3 layer NNets\n",
    "    \"\"\"\n",
    "    h = feedforward_3(X, theta0, theta1)\n",
    "    return -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "\n",
    "c = _multiplecost(X, y, theta0_init, theta1_init)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NNet4:\n",
    "    def __init__(self, learning_rate=0.5, maxepochs=1e4, convergence_thres=1e-5):\n",
    "        \"\"\"\n",
    "        Convenience function:\n",
    "            initialize the NNet parameters\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.maxepochs = int(maxepochs)\n",
    "        self.convergence_thres = 1e-5\n",
    "        \n",
    "    def multiplecost(self, X, y):\n",
    "        l1, l2, l3 = self.feedforward(X)\n",
    "        inner = y * np.log(l3) + (1 - y) * np.log(1- l3)\n",
    "        return -np.mean(inner)\n",
    "    \n",
    "    def feedforward(self, X):\n",
    "        l1 = sigmoid_activation(X.T, self.theta0).T\n",
    "        l1 = np.column_stack([np.ones(l1.shape[0]), l1])\n",
    "        l2 = sigmoid_activation(l1.T, self.theta1).T\n",
    "        l2 = np.column_stack([np.ones(l2.shape[0]), l2])\n",
    "        l3 = sigmoid_activation(l2.T, self.theta2)\n",
    "        return l1, l2, l3\n",
    "    \n",
    "    def predict(self, X):\n",
    "        _,__, y = self.feedforward(X)\n",
    "        return y\n",
    "    \n",
    "    def learn(self, X, y):\n",
    "        nobs, ncols = X.shape\n",
    "        self.theta0 = np.random.normal(0, 0.01, size = (ncols, (ncols - 1)))\n",
    "        self.theta1 = np.random.normal(0, 0.01, size = (ncols , (ncols - 1)))\n",
    "        self.theta2 = np.random.normal(0, 0.01, size = (ncols, 1))\n",
    "        \n",
    "        self.costs = []\n",
    "        cost = self.multiplecost(X, y)\n",
    "        self.costs.append(cost)\n",
    "        costprev = cost + self.convergence_thres + 1\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        for counter in np.arange(self.maxepochs):\n",
    "            l1, l2, l3 = self.feedforward(X)\n",
    "            \n",
    "            # Backpropagation\n",
    "            #l3_delta = (y - l3) * l3 * (1 - l3)\n",
    "            #l2_delta =  l3_delta.T.dot(self.theta2.T) * l2 * (1 - l2)\n",
    "            #l1_delta = l2_delta.T.dot(self.theta1.T) * l1 * (1 - l1)\n",
    "            l3_delta = l3 - y\n",
    "            l2_delta = l3_delta.T.dot(self.theta2.T) * l2 * (1 - l2)\n",
    "            l1_delta = (l2_delta.dot(self.theta1)).T.dot((l1 * (1 - l1)))\n",
    "            # Update parameters\n",
    "            self.theta2 += l2.T.dot(l3_delta.T) / nobs * self.learning_rate\n",
    "            self.theta1 += (l1 * l2_delta) / (nobs * self.learning_rate)\n",
    "            self.theta0 += X.dot(l1_delta.T) / nobs * self.learning_rate\n",
    "            \n",
    "            counter += 1\n",
    "            costprev = cost\n",
    "            cost = self.multiplecost(X, y)\n",
    "            self.costs.append(cost)\n",
    "            if np.abs(costprev - cost) < self.convergence_thres and counter > 500:\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "split = math.floor(X.shape[0] * .8)\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]\n",
    "\n",
    "\n",
    "learning_rate = 0.5\n",
    "maxepochs = 10000\n",
    "convergence_thres = 0.00001\n",
    "\n",
    "_model = NNet4(learning_rate = learning_rate, maxepochs = maxepochs, convergence_thres = convergence_thres)\n",
    "\n",
    "%time _model.learn(X_train, y_train)\n",
    "probabilities_test = _model.predict(X_test)\n",
    "probabilities_train = _model.predict(X_train)\n",
    "auc_train = roc_auc_score(y_train, probabilities_train[0])\n",
    "auc_test = roc_auc_score(y_test, probabilities_test[0])\n",
    "print(\"Train score : {0} \\n Test score : {1}\".format(auc_train, auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "maxepochs = 10000\n",
    "convergence_thres = 0.00001\n",
    "\n",
    "model = NNet3(learning_rate = learning_rate, maxepochs = maxepochs, convergence_thres = convergence_thres)\n",
    "\n",
    "%time model.learn(X, y)\n",
    "\n",
    "plt.plot(model.costs)\n",
    "plt.title(\"Convergence of the cost function for a two layers NNets\")\n",
    "plt.ylabel(\"J($\\Theta$)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8_diffSumClosing stocks(kmt)</th>\n",
       "      <th>6_diffSumClosing stocks(kmt)</th>\n",
       "      <th>county_58</th>\n",
       "      <th>county_53</th>\n",
       "      <th>county_19</th>\n",
       "      <th>county_34</th>\n",
       "      <th>county_20</th>\n",
       "      <th>4_diffSumClosing stocks(kmt)</th>\n",
       "      <th>2_diffSumClosing stocks(kmt)</th>\n",
       "      <th>10_diffSumImports(kmt)</th>\n",
       "      <th>...</th>\n",
       "      <th>7_diffSumProduction(kmt)</th>\n",
       "      <th>12_diffSumExports(kmt)</th>\n",
       "      <th>7_diffSumRefinery intake(kmt)</th>\n",
       "      <th>1_diffSumImports(kmt)</th>\n",
       "      <th>12_diffSumRefinery intake(kmt)</th>\n",
       "      <th>1_diffSumRefinery intake(kmt)</th>\n",
       "      <th>12_diffSumProduction(kmt)</th>\n",
       "      <th>1_diffSumExports(kmt)</th>\n",
       "      <th>1_diffSumProduction(kmt)</th>\n",
       "      <th>actual_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>0.143562</td>\n",
       "      <td>0.094602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.065841</td>\n",
       "      <td>0.098136</td>\n",
       "      <td>1.727903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615302</td>\n",
       "      <td>0.890394</td>\n",
       "      <td>-2.394700</td>\n",
       "      <td>-0.975785</td>\n",
       "      <td>0.477530</td>\n",
       "      <td>-0.194815</td>\n",
       "      <td>0.587627</td>\n",
       "      <td>-1.261073</td>\n",
       "      <td>-0.556181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.350922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.248736</td>\n",
       "      <td>1.160396</td>\n",
       "      <td>0.619888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621748</td>\n",
       "      <td>-1.097692</td>\n",
       "      <td>-0.532956</td>\n",
       "      <td>1.631983</td>\n",
       "      <td>-1.678719</td>\n",
       "      <td>1.323856</td>\n",
       "      <td>-2.149698</td>\n",
       "      <td>0.194216</td>\n",
       "      <td>1.733688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>0.150653</td>\n",
       "      <td>0.634920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695167</td>\n",
       "      <td>0.261343</td>\n",
       "      <td>1.351669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596103</td>\n",
       "      <td>-0.844547</td>\n",
       "      <td>-0.430863</td>\n",
       "      <td>0.681115</td>\n",
       "      <td>-0.645563</td>\n",
       "      <td>0.452519</td>\n",
       "      <td>-1.040750</td>\n",
       "      <td>0.904104</td>\n",
       "      <td>0.962915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>1.197743</td>\n",
       "      <td>0.101970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.219961</td>\n",
       "      <td>-0.341169</td>\n",
       "      <td>-0.275669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688586</td>\n",
       "      <td>1.397428</td>\n",
       "      <td>0.295187</td>\n",
       "      <td>-1.286743</td>\n",
       "      <td>0.107410</td>\n",
       "      <td>-0.514232</td>\n",
       "      <td>0.811423</td>\n",
       "      <td>-1.199302</td>\n",
       "      <td>-1.154385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.302462</td>\n",
       "      <td>0.357674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141038</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>1.214742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793270</td>\n",
       "      <td>-0.875125</td>\n",
       "      <td>-0.320963</td>\n",
       "      <td>-0.080391</td>\n",
       "      <td>-0.730599</td>\n",
       "      <td>-0.757080</td>\n",
       "      <td>-0.544334</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.679002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      8_diffSumClosing stocks(kmt)  6_diffSumClosing stocks(kmt)  county_58  \\\n",
       "6594                      0.143562                      0.094602        0.0   \n",
       "3250                      0.747913                      0.350922        0.0   \n",
       "5716                      0.150653                      0.634920        0.0   \n",
       "5059                      1.197743                      0.101970        0.0   \n",
       "73                        0.302462                      0.357674        0.0   \n",
       "\n",
       "      county_53  county_19  county_34  county_20  \\\n",
       "6594        0.0        0.0        0.0        0.0   \n",
       "3250        0.0        0.0        0.0        0.0   \n",
       "5716        0.0        0.0        0.0        0.0   \n",
       "5059        0.0        0.0        0.0        0.0   \n",
       "73          0.0        0.0        0.0        0.0   \n",
       "\n",
       "      4_diffSumClosing stocks(kmt)  2_diffSumClosing stocks(kmt)  \\\n",
       "6594                     -0.065841                      0.098136   \n",
       "3250                     -0.248736                      1.160396   \n",
       "5716                      0.695167                      0.261343   \n",
       "5059                     -0.219961                     -0.341169   \n",
       "73                        0.141038                      0.078800   \n",
       "\n",
       "      10_diffSumImports(kmt)      ...        7_diffSumProduction(kmt)  \\\n",
       "6594                1.727903      ...                        0.615302   \n",
       "3250                0.619888      ...                       -0.621748   \n",
       "5716                1.351669      ...                       -0.596103   \n",
       "5059               -0.275669      ...                        0.688586   \n",
       "73                  1.214742      ...                       -0.793270   \n",
       "\n",
       "      12_diffSumExports(kmt)  7_diffSumRefinery intake(kmt)  \\\n",
       "6594                0.890394                      -2.394700   \n",
       "3250               -1.097692                      -0.532956   \n",
       "5716               -0.844547                      -0.430863   \n",
       "5059                1.397428                       0.295187   \n",
       "73                 -0.875125                      -0.320963   \n",
       "\n",
       "      1_diffSumImports(kmt)  12_diffSumRefinery intake(kmt)  \\\n",
       "6594              -0.975785                        0.477530   \n",
       "3250               1.631983                       -1.678719   \n",
       "5716               0.681115                       -0.645563   \n",
       "5059              -1.286743                        0.107410   \n",
       "73                -0.080391                       -0.730599   \n",
       "\n",
       "      1_diffSumRefinery intake(kmt)  12_diffSumProduction(kmt)  \\\n",
       "6594                      -0.194815                   0.587627   \n",
       "3250                       1.323856                  -2.149698   \n",
       "5716                       0.452519                  -1.040750   \n",
       "5059                      -0.514232                   0.811423   \n",
       "73                        -0.757080                  -0.544334   \n",
       "\n",
       "      1_diffSumExports(kmt)  1_diffSumProduction(kmt)  actual_labels  \n",
       "6594              -1.261073                 -0.556181              0  \n",
       "3250               0.194216                  1.733688              0  \n",
       "5716               0.904104                  0.962915              1  \n",
       "5059              -1.199302                 -1.154385              1  \n",
       "73                 0.116534                  0.679002              1  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bank_data = bank_data[new_features_bis]\n",
    "shuffled_index = np.random.permutation(_bank_data.index)\n",
    "_bank_data = _bank_data.loc[shuffled_index]\n",
    "split = math.floor(len(_bank_data.index) * .7)\n",
    "train = _bank_data[:split]\n",
    "test = _bank_data[split:]\n",
    "_bank_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89776834529530891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_count = 30\n",
    "\n",
    "bag_proportion = .6\n",
    "\n",
    "predictions = []\n",
    "train_predictions = []\n",
    "\n",
    "for i in np.arange(tree_count):\n",
    "    bag = _bank_data.sample(frac = bag_proportion, random_state = i, replace = True)\n",
    "    clf = DecisionTreeClassifier(random_state = 1, splitter = 'random', max_features = 'auto', max_depth = 50,\n",
    "                                min_samples_leaf = 2)\n",
    "    clf.fit(bag[new_features], bag['actual_labels'])\n",
    "    predictions.append(clf.predict_proba(bank_test[new_features]))\n",
    "    train_predictions.append(clf.predict_proba(train[new_features]))\n",
    "    \n",
    "\n",
    "average_predictions = ((np.sum(predictions, axis = 0)) / tree_count)[:, 1]\n",
    "train_average_predictions = ((np.sum(train_predictions,  axis = 0)) / tree_count)[:, 1]\n",
    "auc_train = roc_auc_score(train['actual_labels'], train_average_predictions)\n",
    "auc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8709356081809035 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_ens = RandomForestClassifier(n_estimators = 30, random_state = 1, min_samples_leaf = 1, max_depth = 30)\n",
    "clf_ens.fit(_bank_data[new_features], _bank_data['actual_labels'])\n",
    "\n",
    "predictions = clf_ens.predict(bank_test[new_features])\n",
    "train_predictions = clf_ens.predict(train[new_features])\n",
    "\n",
    "\n",
    "#auc_score = roc_auc_score(test['actual_labels'], predictions)\n",
    "train_auc_score = roc_auc_score(train['actual_labels'], train_predictions)\n",
    "print(\"train score {0} \".format(train_auc_score  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score : 0.8843166967355461 \n",
      " test score : 0.7727229961506058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_count = 30\n",
    "\n",
    "bag_proportion = .6\n",
    "\n",
    "test_predictions = []\n",
    "train_predictions = []\n",
    "real_predictions = []\n",
    "\n",
    "for i in np.arange(tree_count):\n",
    "    bag = train.sample(frac = bag_proportion, random_state = i, replace = True)\n",
    "    clf = DecisionTreeClassifier(random_state = 1, splitter = 'random', max_features = 'auto', max_depth = 50,\n",
    "                                min_samples_leaf = 2)\n",
    "    clf.fit(bag[new_features], bag['actual_labels'])\n",
    "    test_predictions.append(clf.predict_proba(test[new_features]))\n",
    "    train_predictions.append(clf.predict_proba(train[new_features]))\n",
    "    #real_predictions.append(clf.predict_proba(bank_test[test_labels]))\n",
    "    \n",
    "\n",
    "average_predictions = ((np.sum(test_predictions, axis = 0)) / tree_count)[:, 1]\n",
    "train_average_predictions = ((np.sum(train_predictions,  axis = 0)) / tree_count)[:, 1]\n",
    "#average_predictions_test = ((np.sum(real_predictions,  axis = 0)) / tree_count)[:, 1]\n",
    "auc_test = roc_auc_score(test['actual_labels'], average_predictions)\n",
    "auc_train = roc_auc_score(train['actual_labels'], train_average_predictions)\n",
    "print(\"train score : {0} \\n test score : {1}\".format(auc_train , auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.concat([bank_test['ID'], pd.DataFrame({'Target':probabilities[0]})], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.to_csv('/Users/Kenneth-Aristide/anaconda3/bin/python_prog/ML_Training/data/NN_predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
