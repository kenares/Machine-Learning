{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "we'll explore how to identify overfitting and what you can do to avoid it.<br>\n",
    "\n",
    "1. <b>import data</b>\n",
    "2. <b>Bias And Variance</b>\n",
    "3. <b>Multivariate Models </b>\n",
    "4. <b> Cross Validation </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.core.pylabtools import figsize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import KFold\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "root = r\"/Users/Kenneth-Aristide/anaconda3/bin/python_prog/ML/styles/bmh_matplotlibrc.json\"\n",
    "s = json.load(open(root))\n",
    "matplotlib.rcParams.update(s)\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     model year  origin         car name  \n",
       "393          82       1  ford mustang gl  \n",
       "394          82       2        vw pickup  \n",
       "395          82       1    dodge rampage  \n",
       "396          82       1      ford ranger  \n",
       "397          82       1       chevy s-10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data\n",
    "headers =[\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\",\n",
    "          \"origin\", \"car name\"]\n",
    "\n",
    "_root = '/Users/Kenneth-Aristide/anaconda3/bin/python_prog/ML/data/auto.csv'\n",
    "cars = pd.read_table(_root, delim_whitespace = True, names = headers)\n",
    "filtered_cars = cars[cars['horsepower'] != '?']\n",
    "filtered_cars['horsepower'] = filtered_cars['horsepower'].astype('float')\n",
    "filtered_cars.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias And Variance\n",
    "At the heart of understanding overfitting is understanding $bias$ and $variance$. <b>Bias</b> and <b>variance</b> make up the 2 observable sources of error in a model that we can indirectly control.<br><br>\n",
    "Bias describes error that results in bad assumptions about the learning algorithm. For example, assuming that only one feature, like a car's weight, relates to a car's fuel efficiency will lead you to fit a simple, univariate regression model that will result in high bias. The error rate will be high since a car's fuel efficiency is affected by many other factors besides just its weight.<br><br>\n",
    "Variance describes error that occurs because of the variability of a model's predicted values. If we were given a dataset with 1000 features on each car and used every single feature to train an incredibly complicated multivariate regression model, we will have low bias but <i>high variance</i>.<br><br>\n",
    "In an ideal world, we want low bias and low variance but in reality, there's always a tradeoff.\n",
    "\n",
    "### Bias-Variance Tradeoff\n",
    "\n",
    "We've discussed before how overfitting generally happens when a model performs well on a training set but doesn't generalize well to new data. A key nuance here is that you should think of overfitting as a relative term. Between any 2 models, one will overfit more than the other one.<br><br>\n",
    "Understanding the bias variance tradeoff (https://en.wikipedia.org/wiki/Biasâ€“variance_tradeoff) is critical to understanding overfitting. Every process has some amount of inherent noise that's unobservable. Overfit models tend to capture the noise as well as the signal in a dataset.\n",
    "\n",
    "Scott Fortman Roe's blog post on the bias-variance tradeoff has a wonderful image (http://scott.fortmann-roe.com/docs/BiasVariance.html) that describes this tradeoff:<br><br>\n",
    "<img src=\"http://localhost:8888/files/python_prog/ML/img/over.png\", width = 500/>\n",
    "We can approximate the bias of a model by training a few different models from the same class (linear regression in this case) using different features on the same dataset and calculating their error scores. For regression, we can use mean absolute error, mean squared error, or R-squared.\n",
    "\n",
    "We can calculate the variance of the predicted values for each model we train and we'll observe an increase in variance as we build more complex, multivariate models.\n",
    "\n",
    "While an extremely simple, univariate linear regression model will $underfit$, an extremely complicated, multivariate linear regression model will $overfit$. Depending on the problem you're working on, there's a happy middle ground that will help you construct reliable and useful predictive models.\n",
    "\n",
    "Let's first create a function <i>train_and_test</i>, that we can use for training the model and computing the bias and variance values and use it to train some simple, univariate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test(col_name):\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "        Run simple linear regression, compute and return the variance and error\n",
    "    \"\"\"\n",
    "    features = filtered_cars[col_name]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(features, target)\n",
    "    predictions = lr.predict(features)\n",
    "    \n",
    "    mse = mean_squared_error(target, predictions)\n",
    "    var = np.var(predictions)\n",
    "    return mse, var\n",
    " \n",
    "# train the model using only cylinders\n",
    "cyl_mse, cyl_var = train_and_test([\"cylinders\"])\n",
    "\n",
    "# train the model using only the weight\n",
    "weight_mse, weight_var = train_and_test([\"weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate models\n",
    "Now that we have a function for training a regression model and calculating the mean squared error and variance, let's use it to train and understand more complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_mse, one_var = train_and_test([\"cylinders\"])\n",
    "two_mse, two_var = train_and_test([\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "six_mse, six_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\",\n",
    "                                       \"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "The multivariate regression models we trained got progressively better at reducing the amount of error.\n",
    "\n",
    "A good way to detect if the model is overfitting is to compare the $in-sample-error$ and the $out-of-sample-error$, or the training error with the test error. So far, we calculated the in sample error by testing the model over the same data it was trained on. To calculate the out-of-sample error, we need to test the data on a test set of data. We unfortunately don't have a separate test dataset and we'll instead use cross validation.\n",
    "\n",
    "If a model's cross validation error (out-of-sample error) is much higher than the in sample error, then our data science senses should start to tingle. This is the first line of defense against overfitting and is a clear indicator that the trained model doesn't generalize well outside of the training set.\n",
    "\n",
    "Let's create a new function to handle performing the cross validation and computing the cross validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_cross_val():\n",
    "    \"\"\"\n",
    "    Convenience function:\n",
    "        train a linear regression using KFolds cross validation and \n",
    "        return the average mse and variance across all the folds\n",
    "    \"\"\"\n",
    "    variance_values = []\n",
    "    mse_values = []\n",
    "    \n",
    "    features = filtered_cars[col_name]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    \n",
    "    #initialize the cross validation folds\n",
    "    kf = KFold(features.shape[0], n_folds = 10, shuffle = True, random_state = 3)\n",
    "    \n",
    "    #iterate through over each fold.\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = features.iloc[train_index], features[test_index]\n",
    "        y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        # fit the model and make predictions\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        predictions = lr.predict(X_test)\n",
    "        \n",
    "        # calculate the mse and var\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        var = np.var(predictions)\n",
    "        \n",
    "        variance_values.append(var)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    avg_mse = np.mean(variance_values)\n",
    "    avg_var = np.mean(mse_values)\n",
    "    \n",
    "    return avg_mse, avg_var\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "one_mse, one_var = train_and_test([\"cylinders\"])\n",
    "two_mse, two_var = train_and_test([\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "six_mse, six_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\",\n",
    "                                       \"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtsAAAE4CAYAAACKSD8ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d69d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize(12.5, 5)\n",
    "plt.scatter([2, 3, 4, 5, 6, 7], [two_mse, three_mse, four_mse, five_mse, six_mse, seven_mse], c = \"r\", s=  40)\n",
    "plt.scatter([2, 3, 4, 5, 6, 7], [two_var, three_var, four_var, five_var, six_var, seven_var], c = \"b\", s = 40)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
